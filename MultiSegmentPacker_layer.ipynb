{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOY+WC/BXeYmzBRSDIgzJqO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/0navarro/ml_portfolio/blob/main/MultiSegmentPacker_layer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MultiSegmentPacker Layer"
      ],
      "metadata": {
        "id": "gdXImhjdF7Nd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The MultiSegmentPacker from Keras NLP combines a groups of sequences into an adequate input for models such as BERT. In this notebook I explain the different arguments of the MultiSegmentPacker layer from Keras NLP."
      ],
      "metadata": {
        "id": "H-QFs32pFIRz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install required packages"
      ],
      "metadata": {
        "id": "Dhqcu5NfGvvq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L4NYwZRbSv5",
        "outputId": "80b5edba-9a78-47ab-9b42-f66bb4c2e362"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m508.4/508.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m589.8/589.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.15.1 requires tensorflow<2.16,>=2.15, but you have tensorflow 2.16.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q --upgrade keras-nlp\n",
        "!pip install -q --upgrade keras  # Upgrade to Keras 3.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import Keras NLP package"
      ],
      "metadata": {
        "id": "vrmV_02bINb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_nlp"
      ],
      "metadata": {
        "id": "e38Rh_ALbfGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The MultiSegmentPacker takes a `sequence_length` argument which determines how large the output tensor will be. We also define `start_value` and an `end_value`, that will appear at the beginning and at the end of the packed sequence, respectively. We can define a `pad_value` as well, that will fill up the tensor up to the defined sequence length."
      ],
      "metadata": {
        "id": "VtQ4316WINAU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "packer = keras_nlp.layers.MultiSegmentPacker(\n",
        "    sequence_length=8,\n",
        "    start_value=\"[START]\",\n",
        "    end_value=\"[END]\",\n",
        "    pad_value=\"[PAD]\",\n",
        ")"
      ],
      "metadata": {
        "id": "29A5UcRhIUol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define a test sequence and pack it with our MultiSegmentPacker layer. The layer outputs the packed sequence and a tensor with sequence ids, that helps matching each sequence element in the packed sequence with their corresponding input sequence. Since we have only one input sequence, all the elements have the same id.\n",
        "Notice how the packed sequence starts and ends with the start and end values we defined in the layer. Also notice that the sequence is padded to reach the defined sequence length."
      ],
      "metadata": {
        "id": "YBYTp0l0LSYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequence = [\"a\", \"b\", \"c\", \"d\", \"e\"]\n",
        "packer((sequence,))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMzG9DaZLIN4",
        "outputId": "bb73c147-8961-41e5-fb80-5ca737745204"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=string, numpy=\n",
              " array([b'[START]', b'a', b'b', b'c', b'd', b'e', b'[END]', b'[PAD]'],\n",
              "       dtype=object)>,\n",
              " <tf.Tensor: shape=(8,), dtype=int32, numpy=array([0, 0, 0, 0, 0, 0, 0, 0], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will have two input sequences to explain the last two arguments: `sep_value` and `truncate`. With `sep_value` we can define a value that will separate each input sequence in the packed sequence. `truncate` determines how the package sequence \"budget\", i.e. the sequence length, is distributed among the input sequences. The default value, `\"round_robin\"`, assigns one budget element to each input sequence in a round robin fashion, i.e. first one element to the first sequence, then to the second sequence, then to the first and so on."
      ],
      "metadata": {
        "id": "EhunjulGMfvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequence_1 = [\"a\", \"b\", \"c\", \"d\"]\n",
        "sequence_2 = [\"v\", \"w\", \"x\", \"y\"]\n",
        "packer = keras_nlp.layers.MultiSegmentPacker(\n",
        "    sequence_length=8,\n",
        "    start_value=\"[START]\",\n",
        "    end_value=\"[END]\",\n",
        "    pad_value=\"[PAD]\",\n",
        "    sep_value=\"[SEP]\",\n",
        "    truncate=\"round_robin\"\n",
        ")\n",
        "packer((sequence_1, sequence_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GnvRbjxEriIP",
        "outputId": "45f6debf-57a2-42e5-82a5-754c2929843b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=string, numpy=\n",
              " array([b'[START]', b'a', b'b', b'c', b'[SEP]', b'v', b'w', b'[END]'],\n",
              "       dtype=object)>,\n",
              " <tf.Tensor: shape=(8,), dtype=int32, numpy=array([0, 0, 0, 0, 0, 1, 1, 1], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`truncate` also accepts the value `\"waterfall\"`, which assigns the sequence length budget from left to right. Notice that the second input sequence gets one element budget only after the entire first input sequence is packed.\n",
        "\n",
        "Finally, also notice the output sequence ids. In this case we have six elements belonging to sequence 0 and two elements belonging to sequence 1"
      ],
      "metadata": {
        "id": "-5EGEVTvOEZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "packer = keras_nlp.layers.MultiSegmentPacker(\n",
        "    sequence_length=8,\n",
        "    start_value=\"[START]\",\n",
        "    end_value=\"[END]\",\n",
        "    pad_value=\"[PAD]\",\n",
        "    sep_value=\"[SEP]\",\n",
        "    truncate=\"waterfall\"\n",
        ")\n",
        "packer((sequence_1, sequence_2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q6-KnkLGN5rz",
        "outputId": "6c0a6db1-cece-4658-8bcf-5c8c6a643b8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(8,), dtype=string, numpy=\n",
              " array([b'[START]', b'a', b'b', b'c', b'd', b'[SEP]', b'v', b'[END]'],\n",
              "       dtype=object)>,\n",
              " <tf.Tensor: shape=(8,), dtype=int32, numpy=array([0, 0, 0, 0, 0, 0, 1, 1], dtype=int32)>)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}
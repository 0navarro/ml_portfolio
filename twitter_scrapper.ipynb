{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playwright.async_api import async_playwright\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def scrape_tweet(url: str)->dict:\n",
    "    _xhr_calls = []\n",
    "\n",
    "    async with async_playwright() as pw:\n",
    "\n",
    "        async def intercept_response(response):\n",
    "            if response.request.resource_type == \"xhr\":\n",
    "                _xhr_calls.append(response)\n",
    "\n",
    "        browser = await pw.chromium.launch(headless=True)\n",
    "        #context =  browser.new_context(viewport={\"width\":1920, \"height\":1000})\n",
    "        page = await browser.new_page()\n",
    "        \n",
    "        await page.goto(url)\n",
    "        # enable background request intercepting:\n",
    "        page.on(\"response\", intercept_response)\n",
    "        # go to url and wait for the page to load\n",
    "        \n",
    "        await page.wait_for_selector(\"[data-testid='tweet']\")\n",
    "\n",
    "        # find all tweet background requests:\n",
    "        tweet_calls = [f for f in _xhr_calls if \"TweetResultByRestId\" in f.url]\n",
    "        for xhr in tweet_calls:\n",
    "            data = await xhr.json()\n",
    "            return data[\"data\"][\"tweetResult\"][\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Future exception was never retrieved\n",
      "future: <Future finished exception=TargetClosedError('Target page, context or browser has been closed')>\n",
      "playwright._impl._errors.TargetClosedError: Target page, context or browser has been closed\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'coroutine' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28;01mawait\u001b[39;00m scrape_tweet(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://twitter.com/Scrapfly_dev/status/1664267318053179398\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "Cell \u001b[0;32mIn[18], line 25\u001b[0m, in \u001b[0;36mscrape_tweet\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m xhr \u001b[38;5;129;01min\u001b[39;00m tweet_calls:\n\u001b[1;32m     24\u001b[0m     data \u001b[38;5;241m=\u001b[39m xhr\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtweetResult\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'coroutine' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "print(await scrape_tweet(\"https://twitter.com/Scrapfly_dev/status/1664267318053179398\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
